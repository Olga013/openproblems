import openproblems
import tempfile
import os
import sys
import multiprocessing

N_THREADS = multiprocessing.cpu_count()
TEMPDIR = ".evaluate"
SCRIPTS_DIR = os.getcwd()
DOCKER_DIR = "/opt/openproblems/scripts/"
RESULTS_DIR = os.path.join(SCRIPTS_DIR, "..", "website", "data", "results")
os.environ['SINGULARITY_CACHEDIR'] = "/tmp/.singularity"
SINGULARITY_EXEC = "singularity exec -B {mountdir}:/opt/openproblems docker://singlecellopenproblems/{{image}} /bin/bash {workdir}/singularity_run.sh".format(mountdir=os.path.dirname(SCRIPTS_DIR), workdir=DOCKER_DIR)


def tasks(wildcards):
    return [
        os.path.join(TEMPDIR, "{}.json".format(t.__name__.split(".")[-1]))
        for t in openproblems.TASKS
    ]


def all_methods(wildcards):
    return [
        os.path.join(
            TEMPDIR,
            task.__name__.split(".")[-1],
            dataset.__name__,
            "{}.result.json".format(method.__name__),
        )
        for task in openproblems.TASKS
        for dataset in task.DATASETS
        for method in task.METHODS
    ]


def methods(wildcards):
    task = getattr(openproblems.tasks, wildcards.task)
    return [
        os.path.join(
            TEMPDIR,
            wildcards.task,
            wildcards.dataset,
            "{}.result.json".format(m.__name__),
        )
        for m in task.METHODS
    ]


def metrics(wildcards):
    task = getattr(openproblems.tasks, wildcards.task)
    return [
        os.path.join(
            TEMPDIR,
            wildcards.task,
            wildcards.dataset,
            wildcards.method,
            "{}.metric.json".format(m.__name__),
        )
        for m in task.METRICS
    ]


def datasets(wildcards):
    return [
        os.path.join(
            RESULTS_DIR, task.__name__.split(".")[-1], "{}.json".format(d.__name__)
        )
        for task in openproblems.TASKS
        for d in task.DATASETS
    ]


def docker_image(wildcards):
    task = getattr(openproblems.tasks, wildcards.task)
    try:
        fun = getattr(task.metrics, wildcards.metric)
    except AttributeError:
        fun = getattr(task.methods, wildcards.method)
    return fun.metadata['image']


def docker_push(wildcards):
    return "../docker/{}/.docker_push".format(docker_image(wildcards))


def singularity_command(wildcards, output):
    return SINGULARITY_EXEC.format(image=docker_image(wildcards))


rule all:
    input:
        summary = "{}/../results.json".format(SCRIPTS_DIR),
        website = "{}/complete.temp".format(TEMPDIR),

rule website:
    input: datasets
    output: temp("{}/complete.temp".format(TEMPDIR))
    shell: "touch {output}"

rule summary:
    input:
        script = "collate_all.py",
        methods = all_methods,
    params:
        dir = TEMPDIR
    output: "{}/../results.json".format(SCRIPTS_DIR)
    shell: "python3 {input.script} {params.dir} {output}"

rule collate_dataset:
    input:
        script = "collate_dataset.py",
        methods = methods,
    params:
        dir = TEMPDIR
    output: "{}/{{task}}/{{dataset}}.json".format(RESULTS_DIR)
    shell: "python3 {input.script} {wildcards.task} {wildcards.dataset} {params.dir}/{wildcards.task}/{wildcards.dataset} {output}"

rule collate_method:
    input:
        script = "collate_method.py",
        meta = "{tempdir}/{task}/{dataset}/{method}.meta.json",
        metrics = metrics,
    output: temp("{tempdir}/{task}/{dataset}/{method}.result.json")
    shell: "python3 {input.script} {wildcards.task} {input.meta} {wildcards.tempdir}/{wildcards.task}/{wildcards.dataset}/{wildcards.method} {output}"

rule evaluate_metric:
    input:
        script = "evaluate_metric.py",
        data = "{tempdir}/{task}/{dataset}/{method}.method.h5ad",
        docker = docker_push,
    output: temp("{tempdir}/{task}/{dataset}/{method}/{metric}.metric.json")
    params:
        workdir = DOCKER_DIR,
        singularity = singularity_command
    threads: N_THREADS
    shell: """
    {params.singularity} {params.workdir} {input.script} {wildcards.task} {wildcards.metric} {input.data} {output}
    """

rule run_method:
    input:
        script = "run_method.py",
        data = "{tempdir}/{task}/{dataset}.data.h5ad",
        docker = docker_push,
    output:
        data = temp("{tempdir}/{task}/{dataset}/{method}.method.h5ad"),
        json = temp("{tempdir}/{task}/{dataset}/{method}.meta.json"),
    params:
        workdir = DOCKER_DIR,
        singularity = singularity_command
    threads: N_THREADS
    shell: """
    {params.singularity} {params.workdir} {input.script} {wildcards.task} {wildcards.method} {input.data} {output.data} {output.json}
    """

rule load_dataset:
    input:
        script = "load_dataset.py",
        code = "{}/../openproblems/version.py".format(SCRIPTS_DIR)
    output: temp("{tempdir}/{task}/{dataset}.data.h5ad")
    shell: "python3 {input.script} {wildcards.task} {wildcards.dataset} {output}"

rule login_docker:
    output:
        temp(".docker_login")
    params:
        password=os.environ['DOCKER_PASSWORD']
    shell:
        "docker login --username=singlecellopenproblems --password={params.password} && touch {output}"

rule build_docker:
    input:
        dockerfile="../docker/{image}/Dockerfile",
        login=".docker_login",
    output:
        temp("../docker/{image}/.docker_build")
    shell:
        "docker build -f {input.dockerfile} -t singlecellopenproblems/{wildcards.image} . && touch {output}"

rule push_docker:
    input:
        "../docker/{image}/.docker_build"
    output:
        "../docker/{image}/.docker_push"
    shell:
        "docker push singlecellopenproblems/{wildcards.image} && touch {output}"
